{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import csv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import check_array, check_X_y\n",
    "from sklearn import manifold\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = './train_images'\n",
    "test_img_path = './test_images'\n",
    "train_label_file = 'train.csv'\n",
    "test_label_file = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = []\n",
    "train_label = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Is_Rotate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 0\n",
    "trans_img = 0\n",
    "for file in os.listdir(train_img_path):\n",
    "    img = Image.open(train_img_path + '/' + file)\n",
    "    im = np.array(img).reshape(-1)\n",
    "    train_img.append(im)\n",
    "    if Is_Rotate:\n",
    "        hori_img = transforms.RandomHorizontalFlip()\n",
    "        vert_img = transforms.RandomVerticalFlip()\n",
    "        pil_img_H = hori_img(img)\n",
    "        pil_img_V = vert_img(img)\n",
    "        train_img.append(np.array(pil_img_H).reshape(-1))\n",
    "        train_img.append(np.array(pil_img_V).reshape(-1))\n",
    "train_img = np.array(train_img)\n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7584, 262144)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7584,)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "i = 0\n",
    "with open(train_label_file, newline = '') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        if i != 0:\n",
    "            train_label.append(int(row[1]))\n",
    "            if Is_Rotate:\n",
    "                train_label.append(int(row[1]))\n",
    "                train_label.append(int(row[1]))\n",
    "        i = i + 1\n",
    "train_label = np.array(train_label)\n",
    "train_label.shape"
   ]
  },
  {
   "source": [
    "# Suffle Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_img, train_label = shuffle(train_img, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_accuracy(y, y_hat):\n",
    "    return sum(y == y_hat) / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_decomposition(n_components, train_img):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_img = pca.fit_transform(train_img)\n",
    "    pca_inv_img = pca.inverse_transform(pca_img)\n",
    "    img_compressed = (np.stack(pca_imv_img[-1],axis = 0)).astype(np.uint8)\n",
    "    img_pca = Image.fromarray(img_compressed.reshape(train_img.shape), 'L')\n",
    "    return pca_img, pca_inv_img, img_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(lda, x):\n",
    "    if lda.solver == 'lsqr':\n",
    "        raise NotImplementedError(\"(inverse) transform not implemented for 'lsqr' \"\n",
    "                                  \"solver (use 'svd' or 'eigen').\")\n",
    "    check_is_fitted(lda, ['xbar_', 'scalings_'], all_or_any=any)\n",
    "\n",
    "    inv = np.linalg.pinv(lda.scalings_)\n",
    "\n",
    "    x = check_array(x)\n",
    "    if lda.solver == 'svd':\n",
    "        x_back = np.dot(x, inv) + lda.xbar_\n",
    "    elif lda.solver == 'eigen':\n",
    "        x_back = np.dot(x, inv)\n",
    "\n",
    "    return x_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(n_components, train_img, train_label):\n",
    "    lda = LinearDiscriminantAnalysis(n_components = n_components)\n",
    "    clf = lda.fit(train_img, train_label)\n",
    "    clf_X = clf.transform(train_img)\n",
    "    Xr = inverse_transform(lda, clf_X)\n",
    "    return Xr, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 2528 samples in 268.646s...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TSNE Dimensionality reduction\n",
    "'''\n",
    "def TSNE(n_components, train_img):\n",
    "    # Dimensionality reduction 784->2\n",
    "    tsne = manifold.TSNE(n_components=n_components, init='random',\n",
    "                        random_state=5, verbose=1).fit_transform(train_img)\n",
    "    # x_min, x_max = tsne.min(0), tsne.max(0)\n",
    "\n",
    "    # X_norm = (tsne - x_min) / (x_max - x_min)  # normalization\n",
    "    # plt.figure()\n",
    "    # for i in range(X_norm.shape[0]):\n",
    "    #     plt.text(X_norm[i, 0], X_norm[i, 1], str(train_label[i]), color=plt.cm.Set3(train_label[i]),\n",
    "    #              fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    # plt.xticks([])\n",
    "    # plt.yticks([])\n",
    "    # plt.show()\n",
    "    return tsne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Feature selection using SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.feature_selection import RFE\n",
    "# clf = DecisionTreeClassifier()\n",
    "# selected_train ="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd01baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}